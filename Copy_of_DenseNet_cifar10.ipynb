{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_DenseNet_cifar10_(1) (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVIx_KIigxPV"
      },
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNHw6luQg3gc"
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsO_yGxcg5D8"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB7o3zu1g6eT",
        "outputId": "070e5aa8-a64a-4fb5-fc44-737ec8a0c604"
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lAk_Mw_5-rn",
        "outputId": "833bc0f5-8815-43e6-82d0-9cdf5f7ef4b9"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVkpgHsc5-rp",
        "outputId": "4657e40a-56b0-4fa3-8eac-bb00ff2bbe8a"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee-sge5Kg7vr"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anPCpQWhhGb7"
      },
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "c5Wksy8z5-rw",
        "outputId": "f7e8ca62-5e72-4d5e-e741-edfe88cfde83"
      },
      "source": [
        "#https://arxiv.org/pdf/1608.06993.pdf\n",
        "from IPython.display import IFrame, YouTubeVideo\n",
        "YouTubeVideo(id='-W6y8xnd--U', width=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2MBERISGBUYLxoaL2NCOEJjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAQQCAwUGB//EAEsQAAIBAwAECAoGBwYGAwAAAAABAgMEEQUSITEGExQWQVFx0iIyVFVhgZGho9EVIzNSscEXNEJyk6LwJFNzgpLhQ0RiY4PxB2Sy/8QAGQEBAQEBAQEAAAAAAAAAAAAAAAECAwQF/8QAIxEBAQACAQQCAgMAAAAAAAAAAAECEQMSITFRBEETUhQyYf/aAAwDAQACEQMRAD8A+fgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+qQ4H6Ca22Pxp94z5m6B8g+NU7wTb5QD6yuBmgPIPjVO8TzM0B5B8ap3gbfJQfW+ZfB/zf8ap3hzL4P8Am/41TvA2+SA+ucy+D/m/41TvDmVwf83/ABqneBt8jB9d5lcHvN/xqneHMrg95v8AjVO8Db5ED69zJ4Peb/jVO8OZPB7zf8ap3gbfIQfX+ZPB7zf8ap3hzJ4Peb/jVO8Db5AD6/zJ4Peb/jVO8OZPB7zf8ap3gr5AD6/zJ4Peb/jVO8OZPB7zf8ap3gPkAPr/ADJ4Peb/AI1TvDmTwe83/Gqd4D5AD6/zJ4Peb/jVO8OZPB7zf8ap3gPkAPr/ADJ4Peb/AI1TvDmTwe83/Gqd4D5AD6/zJ4Peb/jVO8OZPB7zf8ap3gm3yAH1/mTwe83/ABqneI5k8HvN/wAap3gbfIQfXuZPB7zf8ap3hzJ4Peb/AI1TvA2+Qg+u8yuD3m/41TvDmVwf83/Gqd4G3yIH1zmVwe83/Gqd4cy+D/m/41TvA2+Rg+ucy+D/AJv+NU7xHMvg/wCQfGqd4G3yQH1p8DOD/kHxqneI5maA8g+NU7wNvkwPrD4G6A8g+NU7xg+B2gcP+wfGqd4G3yoF52cMvDwhyKPWFUQXuRQ+8SrGL6X7CbXVUAdNaNj+1PHqMZaPpp7Jv2DcNVzgdDkEPvP2GyjouNWeqpteobhquWDufQdLLTr4x6CvV0XGnPV18+nBJlKtxscsHUqaK4vxm8P0GvkEfve4u4mq54OgrCGV4T9hl9H0v7x+wbhquaDocgp58d47A7CGMqT2egbNOeC7yOPWOSR6ymlIFzkkesxnbxjHIR9nprwUbUjCkvBRtQYEicEgKkYJQAYBIAYJAAAEhUAkAAAAAAUAAAABAAAAABAJAEAAIEEgDHAJIAhkGTICMWiMGbICtckYyXgvsNjRjJeCyo+QY2kodJKMV1jKCTe027YrwY4NSMlJrcyNDb6SDYpRl4y9hDhFvZL2k2rAu6OXhSKvFS6NvYbrOfFVlrbEyZd4Ty21ac6lWo9yRVnnO3oOnKEuOk0swljJWubZxblrRx0GccmrG6cVW0epdKNNlbRqQnKa2I36O+soVKTNkY8RYt7mzNutxdb7uXTocbW1IvG9omra1KcdbGV6Dfo/bdLsZZpuTuJ05LMdpu5WVmSOPgReHtL1KjHlcoNJoyna0p60YbJovVE6XOnHEvwMGjc1huEtmPca5LVZuVlrZrrfZs2s1V/s2VK+y0/FRsMKe5GwrkIkIkKEgAUpV5cp4xa/FKXF7vB7fbsCiuTVKzqTjNOb1tZ7MN9Bc1I6mpqrVxjHQYK2oqWtxUc5zu6QK6qTf1Em1OTUs52qO9/IilXm62vJT4urlLK2Lq9vyLsqcJPMop7MbugOEZRw4prqCqEatSnYR4ybevTTjNvbnG5m6UKcLiUpOajGGs/DfX2ll04OnxbgnDGNXGwOnCW2UUwKCr1qcJ6+vFzWsnJeLt247Ft9ptrqFCm9V1daUZJS121nDfX6C3KMZYyk8bUa1bUU9lKPVuCototQ2wlHKW+etkQlLjK+NuJpJN7tiM6dKFPOpFLJLpwecxW15fpYFe4ThW42etKkkvFk1qvO/HSRGlFXVVZniMItLXe/wvT6CxOjTnNTlCLktzaMtWOW8LLWGwObTqVadJPwoZpxfhT1s7VmW3qRZqQVDi5U5TcnNLDm3rJvb7tvqLHFwxFaqxHds3GMKFKnLWhTin6FuApqrUpWUnUm3GUG4zb2xfV8jbFca6rqOcnB4UYyawsdpZdODpum4pwaw4tbMEToUqjzOCb3ZA01KmbWnKEpRjPVWs96TNdzq0YzhDjVKUcp67w9q9Jc1IqGpqrVxjGNmDCNtRjnFOO3ZuAqxqzpRrLElPKUIOWs8vp7PkRGUnTjRm6mY1IrMm05Rf8AXuLrpwc1NxTlHc8biJ0qdTx4KXaBUrt0ampTnLVcctOTePCS9+WY+Hye4niaf1mJ8Y+t9BdjRpxi1GEUnv2byOT0k2+LW3OfTneBWqVJwjClUk9Zzjqy3ayyveZ0aUVc1ds/BxjM2+jtLEoRljWinh5WehkqKTbS2veEVWpSuqmxtRS267WNnURry5Fbtya11BSnnasr+vaW9VZbwsvea40KUE1GnFJrGOjAFevTdNwjRnJSnlYcm+jOfbgw5S5SVxrONGGIzXpe9+rZ7y5CjTptuEFFvpQ4uGq46q1XnKxsYRhb6zpKU860vCw+jPQbCQBDIJICMWYy8V9hmzGXivsKr5B0koglIxXWJJAIoCQAUmjYqslvee01jeQX6N1KnlSjlPBbV3QqLVqRx2o58aji3rQ6jXWuaK1ceN04Ri4yt706Fuo0brMJJ05encZ6TkuKjGO7ec5VqVVPi3h57DdqzUMqT3Zwya77N9tMdG/rcexlqreRpSlHV2p7zTSThKFSGrJ4baRrqRVeUp4ktu0WS03ZNRNpPjLtt9JajQSqyq63qKlpq066k5bCxSm3dyw8xlsyMljmXElKvKUdzZrzlYlu/A3XdPi7ia6M7CuzrHOkouLNFf7NlhSxszsNVylxTafqDNfYqfio2mFNbEbDbkEgBUgAASAFAAFAAAAJAAACCQAAAAAAAAAIAAAAAASQABJAAgkBEEGRARDIJAGLMZLwX2GbIl4r7APjxKGCcGK6hJBIUAAAlEEkGadSWVBSlJrcllnR0Vo63q2ylVjrSlvx+yUrOu7a4jUis9GO09NRjSp2a4yMXuxk1J2bwm64+k9CUrSnx9CbWrtcW96KMZSawpdB3NMulTslJSlmo8audh53Jjyuepey9Qg6UVUefCi8I2UJYoRx0y2lCF1Vg4pS3JmdG6dPKaym8mbjUlixTjBXc4SjlPcaqEoxqyUpOK9BhTr/ANp4yW7Ipas7na0o5Gk2m98GqlJ6+zsKz4t9DRlcz4ytKXsNLNydmbWWrB7pe00XMWqL7TYarh/VMqV9mp7kbDCn4qMzbkEgkAAAoAAoAAAAAAiUlGLlJpJb2ytyipX2WsPB/vZrwfUun8ALMpxhFynJRit7bwV+Wqf6vSqVv+pLEfa/yMXb0KbVW6qcZJbdaq9i7FuRly+2/Zm5/wCHBy/BAMXs+mjR7E5v8hyaq/HvK3+VRX5DlsOilX/hS+Q5fRXjKrH96lJfkA5Eum4uH/5GOSSXi3Vwv8yf4o2UrqhVeKdaEn1KW0mrXo0ftasIfvPAGrirqPiXMZeipT/NYHH3NP7W21l10pZ9zx+Y5dRb8BVZ/u0pNe3A5Z/9e4/0AZ0rqjWlqwn4fTCWyS9TNxSq3FpVWrcUp7NznRls9eNhFJyW2zuYVor/AIdSWX7d/tyBeBopXUJz4ucZUqv3J9PY9zN4AAASAAIBIAgEkAAAEQCSAiGYy8V9hmYy8R9gHySKzFE6plBeAuwywc3Zr1CNQ3apGqTatOoQ4s36pjgo0jDe42tBTw8dBrHG1L2ZW1OKuaUarwpNM9VO3VOk5Rw6ajlp9B5OrmpSUfu7n1FyOl60tFztqu2TjiMuvtNZTXhrCz7Vru5lczzLCivFityNGXjGTPVTpx6JdJEacmYvZO9asrK2bfQMrJujbtyWX7C1U0RUbap1KcupOWJE6o10Zac8jJZno69pRzK2m0uraV3GUfGi0/SsFYss8sWQySGEQabj7Jm5mq4+yZUr7RT8VGZhT8VGZpzSAAoAAoAAAAAGqvcRo4jhzqS8WEd7/rrNN7ext04RceM6W90e38l0lChKpXcuKVSet40k8OXbLcl6FtAsylxlX6/NxVW6hT8WHa92e31I38Vc1vtKqox+5S2v2v8AJGNO2uFDVVSnQh0Rowy1638jNWefHuLiT/fx+GAMqdlb03rcWpS+9Pwn7Wb1sKzs8eLcXEX16+fxya60ri0p67uIVIroqRxJvqTXyAuled2td06EXWqLeo7o9r/plCrfa09W+17SDWY01tc/WvwLdN13BRt7eFCmtzqd1fMCKli7v9clFr7lNYXt3+zAjo2nQm52knSk9+fDT9u32M2cnuJePeTT/wC3CKXvTHJJ+WXHtj8gI5RVo/rNLwf7yn4S9a3osU5wqQU4SUovc08o0cRdQX1d1r/4tNP8MFG4rStqzxTcK7WcUPDUv3o7/X7wOuaqttRrfaUoSfXjavWULa+r3klBypW7f+dy68Pdn0by3yPWX1lxXn/n1f8A84A11bGThq06jlD7lbwl6nvXtNEbutZSUbmE3T6G9rXZLp9e3tLasKS3Trp/40vmRK1rKLULmUk/2a0VJfk/eBYpVYVqanTkpRfSjI4VWhd6PqOvbQ1F+3TTcqcvzi/cdLR+kaN/TzTerUj49N74/wC3pAuAgkAAAAAAgAAAAEQzGXiPsMzGfiPsCPlNPxI9hmjCn4kewzRxvl6InBGDIE2rHBGqZkMqaapQk1iMW+xZNM9iz1HV0fFzuYR6E8m3hNOgoUIwhFVMvWeNp2wzk7JcLZ1ONGeTDKWV6TFSSN1O2dR5nsXUayykTHG3wwc51Hq012stQXg7TJQjHYlhIlI8+WfU9GGHShLajs1Kes9yew5MYp4OxXerTcktqjn3HKuuLQoThti5R/dlgSnVeyUtZdU4pm3GVvJwF0ozo0Zt69tTfpi3Eq1rK2UXL6ymvQ1JHWcE+gq3lNK3n2FmVZuEca6tlRinGbkm+rBSuPsmde/X1VP1fgjlXUcUWdsbt5OSavZ9np+KZmEPFRmdHEAAUAAAAADn6S0jyeUbehF1Lqfiwjtx6TPSN7yaKp0dV15rZrPCgvvP0FbR9rOkpToRzUqbalzXW2fZHq9gEWeiHKSrX8+MnnKpJ+Cu3rZ1opRSUUkluSK/I9bbWr1qj/f1V7FgcgtvuNenXfzAsklXktSntoXFSP8A01Hrr37feaLrSfIaf9qpNVHsgobVUfUur1gWrq6hbU9aW2T8WOd5So07i6nx0panVPG5dUE93a95ot4zrVnWuIO4uG/s4+JT6k3u2dR0eKu6n2leNJfdpRz738gNlK1o0otRgnreM5bXLtfSanQqW3hWrzDpoyez/K+j8CeR533Fw3+/j8ByatH7K6n2VEpL8n7wNtCvCvFuOU1slF7HF9TNjaSbbwkc64lUpvja0FSnFbK9PbHHVJb8e3tNML6N80qkZNLDVvDa6n/U/wDp6vf1AXOMq3bxQbp0emrjbL935m+jQp0I6tOOM7W+lv0vpNKjd1d84UI9UVrS9r2e4nkafj3FxJ/4jX4YAi7sKN0m5Jwn9+OxlaldXFhNUdINTpN4hcrd2S6u0tckcfs7mvHtnrfjkxmrqEXGcKdzTexrGrJrs3P3AW96ygcqlc07HOJPky8anPZKj6umJajWr3KUreKp0nuqTWW+yPzAtnOvNE061VXNtLk91HaqkVsfaukscjUvta9eo/33FexYHIaP7M60X1qrL5gYWd5Oc+T3cFSuYrcvFmuuJcKFzZ1p08Kpxyi8x1vBnF9akvkRY6Q4yq7W5zC5ispSWNddYHRBBIAAAQCQBAAAGM/EfYZET8SXYEfJ4eIuwzRrp+Kuw2I413jJEmJOSKkgkgDda1OKrKWcek6N7G3vrRyqrwoJuM1vRyCvUrShV1Yzks71nYzWM35WZWdk0qUYvO9lmGxGpbEbo7jnba7SaY9YWQSkRUx3o7NdZt5YW3U/I5EPGOzV1dRJzdN4W1ErWKk5VE5JRzPWT8H0JdZlG4Udm2W1+rq+RthTqRcmq8JZfTH0egSpz2/V0nl5ym1+Q7HdqjcOanHMdZNLZ1ZwY3D1rOo31YNjg5KEXRmtXc4tMxuFi0qLDWx7wObeLNCn2L8Dl3n2Eu1HWu1/Z6b9C/A5V7+ry9R1weXl8vskNxkYw3IyOzzhJBIVW0jVnQ0fcVabxOFOUovGdqR4mjp/Tlwvqrqm3hvHFx+R7PSqb0XdpLLdKWF6jxuiY01CDnHDzteN205c3JcMZY68PFOTPVdDRemdLwvqUb9Rq0arUcKKi4tvCftO/pHSdOylCioudxV2UoL9p+l9BxbiFN3NpOnDOa0NuM4Wuuk7F7omnd39C7dWpCpS2LGMY/pk4c8s5eo5eOYWSIsdGunN3F5Pjrmby3+zH0Jeg6JW5JLyu49q+RlC2lCak7mtLHRJrD9x2cnnNe8uLyvCnc1Vqye+tJLBsVDScZKULqWsnla1aTXrWNpFkmtJ3aknFpvY1jqOmfG5/k8nHyWSvRjhLNts9K0Lewp3N21Tc08RWXl9SKdro+vpGu7zSS1IyWKdH7sep9RlLRVPSdjaOpUnB0m2sbt50OSS8ruPavkfYxu5K89a4r6OSj/ym5Ppp9vo/A4/C6+urN23Ja8qespZ1Xv3HcdnJpp3Vdp9DcfkeZ4X2zoW9nGHGTp01Ja0tuN2FkXw68MlzkrkfS2lvLqn+o9FwY0vcXCq0LySnxcXPjc7cek8odzgpTjWu7mnPOrOi4vDxsyjz8fJblqvsfM+JxcfDc8Z3dzlMtL1nC0f9lg/CqtbJP8AP+vXnW0W6GK2jpaleO1qT2VOvPaTYaGhYU506NzXUJS1sLHyLXJJeV3HtXyPS+EWd2rqi3qunUhsqU5b4M8bTv8ASdZvUvJrGN8mexhYxp3DuONqyqauq9ZravThHi7GMozqxnFxksJqSw1vN4xx5bZNxaoXulqNaFSVyqkYvLhKTakj1PL6So0nL7WrBSjSjtk89R5d+K+w7a0TTu1Y3fHVKdWlSglqvZjAymk4c7lva27FXLVW88KovEUXhU+z0+krxlW0VW1avh2Un9ol9m/Suouckl5Xce1fIOzbTTuq7T6G4/Iw7vO8N6s4KydKpKKlr+K8Z3Hl3O48pq/6n8z03C+wnSsrPiYznSouScm86ucY/A80950x8MZPUcDr65nUqWlapxlOEdeLlvW3d7z0N5ZUryCU8xnF5hUjslB9aZ47g3au7ubilGvUot0vGpvbvR7CNnJRS5XcbFjevkZy8tTwi0uZ8Y7a6wriKymt1Rda/NFlzipKLzl9SK0rBTlCUriu5QeYvMdnuN06LlOL1lsWNqMq25XWRKSjFybwkss0O1jjZq52b45RnToKnCS2Nvpa9AGyM1JZWfWsE5XWU6ltNJY8PrXQvaZO02RUZJJYzs3tdIFqLUoprantRJjTjqQjHfhYMgIIn4kuwkifiS7APksH4KM4s1Q8VGyLOVdY2EmCZkiKkgkgihVrL65dqLRQl+t/5jeH2zV5GxbjXE2x3HKvSxWTKIRMcEGS8ZYO/UowaTcU9i/A4KXhI9BVnFT1ZSknhboNr3Ga1FaVCEk0o+wwdun4spR7Dc6lNf8AEiu3K/ERcJbpwfZNBVeVKpt1Z46DRcqrxM02mknll2S2bMsrXWeJnjOcMTyVzLv9VpdiOTefq77UdW6/U6fYvzOTefYPtO+Dy8vl9mh4qMjGHioyOrzwJACoKEtDWbbahOOW3iM2lt9BfJJZtZbPClDRdvDUxxuINNJ1HjY8ouEga0W2+UAkFRXrWVvXqcZUg9fGNaMnF49Rr+jbb7tT+LL5lwGbjL5hthSpQo0406axGOxLJmAaA1XFvSuqMqNeCnCSw0zaAOTzc0X5O/8AXL5liy0VZ2FSVS2pOEpLDes3s9ZeBNRu8ueU1bQAFYQU7jRVpc1nVqU3rtYbjJxz7C6Alm/Lm/Qdj9yp/Fl8zoU4Rp04wgsRikkvQZAEkngAAVhUhCrBwqRUoyWGmsplb6K0f5Fb/wANFwgDRQsrW2k5ULelSk1huEUjeAAAAAAAACQAAAgNZWGABwObeivJf55fMnm5oryb+eXzOqAOVzd0X5N/PL5k83tGeT/zy+Z1ANQ25n0Bo3GOTfzP5j6A0Z5N/M/mdMDUXdcz6A0Z5N/O/mYc29EuWtyRZ351pfM6pGtHONZZ6sjUNud9AaM8m/mfzJ+gdG+T/wAz+Z0gTUXqvtzfoHRvk/8AM/mFoLRy/wCX/mfzLV3eW9lSdS5qxpxXW9r7Ecarww0fCL4unWqSzsWqkmXpno677dD6D0ev+X/mfzLKs6CedT3lLRGnbbSspU4J06scvUl0rrOoTpno68vbQ7K3lvpp+swejbSW+jF9pbA6cfR15e1F6HsH/wAvH1Noj6Hsv7qS/wA8vmXwOmejry9udU0Ho6qsTt9ZemT+ZpnwZ0RNYlaJr96XzOuC6iW2t8NyMjGHioyDMSAAqCSABIIAEggASCABIIAEg11Z8XDW9K/E18pX93Lfjo3/ANMCwCurnwsar9C6cmUKspznFR2xW9+v5AbgV53Dg8ODeHhtdn/ocqWccXU9nT1AWAauOWopar34foMZXMVjEZPwdZ46EBvBojcKTxGnP0bMZQ5THOxNrZtA3grq5TS8GTzsT2bWbISlPEtij1dP9bwNhBJAAAAAAAAAAkgkAAAIHQABWANdevSt6bqVqkYQXTJ4KNhQ0tpSjoq2VWqnKUniEFvbOJpPhPV4xw0ekoL/AIkllv1HnrircXdTXr1Z1JN/tPcamFYucdiHCvSVapKNG1pzb8WMYttfMrX2mNO0561eVS2U90VDVXvO5W1ODmiKUbalGVzVaTk1veNr/wBjgaUr6Rq1NS/eZYTSxhJPaWTZctKtatpS+1ricripFb5RT1Vjs2IpwdXjVKnKfGZ2OLecnq+B9df2iyqeLJa8V7n+RU0Popx4RypTWY20nLb6N35FTe3Ir1tJ0VGNerd087YqcpL2ZN6jpycNnL3FrG+e4tcJbh3mlppPMKPgR7en3nodO3N9b2ts7Bz1m8S1Ya2zHYDbwtxGuqmLlVFP/uZz7zKjZXNxHWoW9WpHdmMG0ev4QQdfg9Rq3kIxu049uelewcH+Np8G67oZ41ObhhZecLA32X708pGlfaOrQuOJrUZQeVKUGkes0VwqoXPgXqjbzW6WfBl8jfoqrezsbh6aSVLGx1IqLa6dh4qdNa71V4OdnYNbS3T6bSq061NVKU4zg90ovKMz5vZ3d3Yy1ratKHWt6fqPR2PCpNat7R1X9+n0+ozcKszj0oOba6csLptRrKm1/eeDkvwq05w14VISj1p5RnVa3GYIJIrdB+CjIwpvwUZhlIADQAAAAAAAAAAAAANJrDWUYzpwnHDisZTMgBjxcMY1I47CVCKeVFJ7iQBi6cJPLjFvdloiVGnJY1F7DMAY8XDVUdVYW5YMeIpaylqRyvQbABChCLbUUm+pEcXB/srr3GQAxVOCllRjnrwZLC3AAAAAAAAAAAAAJIJAAgAAQwEcbSGkZ0INW1GVSed7i8I8ve1K95WdSvJuT/Z6F2I9yYuEXvivYdcc8cfpx5OPPLxk8CraT3Rb9RlySotupJeo95qx+6vYNSH3V7Df5cfTn/Hy/ZzJpaWsaUqU1TuKTUsSW59XYV6+gncxU6rjxr2yVPwVJ+vP4HVrTdKouLpayxmWF6V/uYU7ms6sYyota72dGqtVN59rOfV6d+jf9nmaFvW0XpOnUnTcYxlh9Kx07T0deFOz5VewXhzgvatxsc6sqk0oJxjOKWYNZTe3/wBkV61aMsU6Wt4DeHF4z0bV+AuW2ccLjvu8U6LlJuWW28s9Vpi8uLO3oO3aTlseVnoNl5C5nbQrRuoWcYwcqjdNS2+vcUvpa6jwchdzhHlE5akG44W/Y8G7lLZdMY8eWMs249zK8vpqVdzqY3LV2L1Hb0RCrQ0FX1VKNROTjs25wbbG4uaOlp6Puqyr5pKrGeqotda2GNrc3q0/O0uKtOVPieMUYRwltwhllLNSLhhZd2o0dKppPR9e2vfCmtzksP0M81Us6lKbhODUl0NHpNNzvLOMq9G+1deSjToqim230ZOrbRqK2pq4anV1VryxvZJnMe+jLiyykm+8eFVrOW6DfYjbHRlzLxaFR9kWe6wuokv5p6Znx795PC/RdznHETz+6yXo27itXiamP3We4BPy/wCL/Hv7PLWM9L2i1adOpKH3akW0j0NrdTrQXG0KlKfSmthZBjLKX6dcMLj9sqb8FGzJ5yHDPQCW2/8Ag1O6Zc9OD/nD4NTumGnokycnnlw14P8AnD4NTuk89eD3nD4NTugehB57ntwe84fBqd0nntwe84fBqd0K9CDz3Pbg95w+DU7o57cHvOHwandCvQg8/wA9+D3nD4NTujnvwe84fBqd0D0APP8APfg95w+DU7o578HvOHwandA9ADz/AD34PecPg1O6Oe/B7zh8Gp3QPQA8/wA9uDvnD4NTujntwd84fBqd0D0APP8APbg75w+DU7o57cHfOHwandA9ADz/AD24O+cPg1O6Oe3B3zh8Gp3QPQA8/wA9uDvnD4NTujntwd84fBqd0Ds17mFCUVNPDWW10f1k1vSFulvl/pZyXw14ON5d+m/8Cp3TF8MuDTkpcujlbvqKndA7avKOpGTk0pPV2rpMVpC3bxrSzt/ZZxlwz4NqKSvlhf8AYqd0R4ZcGo7r5Lbn7Cp3QOy7+3T2yf8ApZEr+lGHGYk4a2rnHoznsORz04N+XL+BU7pPPTg5j9fX8Cp3QOzSu6VV6sdbPTlbjBX9LV1p5jnoxnoT6O05HPPg35cv4FTukLhlwaSSV8tmz7Cp3QO3VuoUlTbTaqbv9wrunKhKrHLSeN2NucHF558G0sK+WP8AAqd0c8+DeX/blt3/AFFTb/KB1XpGgsbW3szjoJekbdPfLGMt6r2HJ558G/Ll/Aqd0xjww4MxcnG9Sct/1FTugdyV1T4iVWOWo7MPZlmtaQo7p60ZZa1cZ3HI558G9v8Abo7f+xU7pPPPg35cv4FTugdnllOVGpUp5nqLLWMZIje05Zwm8Lbjr2bPecSHDDgzTcnC9Scnl/UVNv8AKHwx4N5b5csvf9TU7oR1/pCDk46ks4zsa68GyncxqVJU1FpptezHzOJzy4OLdfJf+Cp3SFwy4Op5V8k/8Gp3QjuA+eVP/kC8VSSp0beUE3qvEtq9pj+kC/8A7i39kvmGn0UHzr9IF/8A3Fv7JfMfpAv/ACe39kvmB9ClDWlnWa2YwjFUmnF68vBz6z5/+kC/8nt/ZL5j9IN/5Pb+yXzLtNR9BjTcUlrt4yFTajhzb2NZPn36QL7ye39kvmP0g3/k9v7JfMbNR7LSeip6RjTjK7nThDa4qKak+tmc9Gcfo6VpdV5VcvMZ6qi443YSPFfpBv8Aye39kvmP0g3/AJPb+yXzL1U1HtbLRrt7mdzWuJXFecVDWlFLEV0YNisEtKu/4x6zpcXqY2b85PDfpBv/ACe39kvmbqHD6vJS4+nRhjdqwbz7+wm6aezrWCr6Qo3VSo3GinqU8bE+suHg58PZcZTUFTcHra7dN5XVjb0k1uHso54lU57NmtTa/MK92DwVPh7VlTi6ipQnjalSb/PsMqXD2Tt26vFxrY2RVNtZ7c9hB7sHg48PpPjNaMVjGolTe33mEuH1fiNaNOi6v3XB439eeoD34PDc/FrQ2w1dus1SezqxtMY8PJca1Li9TKw1TeXv9PYB4QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH//2Q==\n",
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/-W6y8xnd--U\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f844c8b1898>"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kFh7pdxhNtT",
        "scrolled": true,
        "outputId": "262f78c0-257c-4bd9-aa76-6570ce948d04"
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 6)    648         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 6)    972         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1296        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1620        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1944        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2268        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2592        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2916        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3240        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3564        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3888        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4212        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 6)    324         activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 6)    648         activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 6)    972         activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 6)    1296        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
            "                                                                 dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 6)    1620        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 6)    1944        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 6)    2268        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 6)    2592        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 6)    2916        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 6)    3240        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 6)    3564        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 6)    3888        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 6)      324         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 6)      648         activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 6)      972         activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 6)      1296        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
            "                                                                 dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 6)      1620        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 6)      1944        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 6)      2268        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
            "                                                                 dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 6)      2592        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
            "                                                                 dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 6)      2916        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
            "                                                                 dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 6)      3240        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 6)      3564        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 6)      3888        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 6)      324         activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 6)      648         activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
            "                                                                 dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 6)      972         activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
            "                                                                 dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 6)      1296        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 6)      1620        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 6)      1944        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
            "                                                                 dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 6)      2268        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
            "                                                                 dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 6)      2592        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 6)      2916        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 6)      3240        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 6)      3564        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
            "                                                                 dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 6)      3888        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
            "                                                                 dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 118,918\n",
            "Trainable params: 114,394\n",
            "Non-trainable params: 4,524\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8Aqzk9AFXb1y",
        "outputId": "edb9053d-7b21-4a3b-ec99-4b4dd25604ea"
      },
      "source": [
        "print(len(model.layers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XOsW3ahSkL"
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1771
        },
        "id": "crhGk7kEhXAz",
        "scrolled": true,
        "outputId": "e3e2d0d0-1492-41ab-df5b-5a7ecd705c2c"
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1, \n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 4404s 88ms/sample - loss: 1.7059 - accuracy: 0.3568 - val_loss: 1.6560 - val_accuracy: 0.4044\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 3571s 71ms/sample - loss: 1.3596 - accuracy: 0.4974 - val_loss: 1.3628 - val_accuracy: 0.5203\n",
            "Epoch 3/10\n",
            " 5632/50000 [==>...........................] - ETA: 46:21 - loss: 1.2483 - accuracy: 0.5424"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-9a2ac61b9ade>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     validation_data=(X_test, y_test))\n\u001b[0m",
            "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3217\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[0;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
            "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 415\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    416\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "ZcWydmIVhZGr",
        "outputId": "a0345aa5-79ff-4e56-eb94-50437b43c4fe"
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1.4938 - accuracy: 0.4969\n",
            "Test loss: 1.493803402900696\n",
            "Test accuracy: 0.4969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3lF6EH1r_L"
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8pwPVTLH56Q"
      },
      "source": [
        "### Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9DmWpfIXc99"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWuIG72aH7he"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "l = 20\n",
        "num_filter = 16\n",
        "compression = 0.5\n",
        "dropout_rate = 0"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h2uXg5AYPv4"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZH16jh9KzLZ"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12, dropout_rate = 0):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQqDnJw3MBAD"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "train_norm= X_train.astype('float32') \n",
        "test_norm= X_test.astype('float32')\n",
        "\n",
        "X_train= train_norm/255.0 #rescaling between 0 and 1\n",
        "X_test= test_norm/255.0\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-xCqN5ULpfC"
      },
      "source": [
        "\n",
        "tf.keras.backend.clear_session()\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGJxYuCvWzsk"
      },
      "source": [
        "filepath=\"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4QaD164IwYq",
        "outputId": "a92d2325-6505-4b39-ec20-ac3bc31af7ac"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             width_shift_range=0.15,\n",
        "                             height_shift_range=0.15,\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   432         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 8)    1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 24)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 8)    1728        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 32)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 8)    2304        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 40)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 40)   160         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 40)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 8)    2880        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 48)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 8)    3456        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 56)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 56)   224         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 56)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 8)    4032        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 64)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 8)    4608        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 72)   0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 72)   288         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 72)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 8)    5184        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 80)   0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 80)   320         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 80)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 8)    5760        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 88)   0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 88)   352         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 88)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 8)    6336        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 96)   0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 96)   384         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 8)    6912        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 104)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 104)  416         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 104)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 8)    7488        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 112)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 112)  448         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 112)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 8)    8064        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 120)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 120)  480         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 120)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 8)    8640        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 128)  0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 128)  512         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 8)    9216        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 136)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 136)  544         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 136)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 8)    9792        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 144)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 144)  576         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 144)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 8)    10368       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 32, 32, 152)  0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 152)  608         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 152)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 8)    10944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 32, 32, 160)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 160)  640         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 160)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 8)    11520       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 32, 32, 168)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 168)  672         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 168)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 8)    12096       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 32, 32, 176)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 176)  704         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 176)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 8)    1408        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 8)    0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 8)    32          average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 8)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 8)    576         activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 16)   0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 16)   64          concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 16)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 8)    1152        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 24)   0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 24)   96          concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 24)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 8)    1728        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 32)   0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 8)    2304        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 40)   0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 40)   160         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 40)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 8)    2880        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 48)   0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 48)   192         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 48)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 8)    3456        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 56)   0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 56)   224         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 56)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 8)    4032        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 64)   0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 64)   256         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 8)    4608        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 72)   0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 72)   288         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 72)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 8)    5184        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 80)   0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 80)   320         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 80)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 8)    5760        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 88)   0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 88)   352         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 88)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 8)    6336        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 96)   0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 96)   384         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 96)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 8)    6912        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 104)  0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 104)  416         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 104)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 8)    7488        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 16, 16, 112)  0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 112)  448         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 112)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 8)    8064        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 16, 16, 120)  0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 120)  480         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 120)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 8)    8640        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 16, 16, 128)  0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 128)  512         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 8)    9216        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 16, 16, 136)  0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 136)  544         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 136)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 8)    9792        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 16, 16, 144)  0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 144)  576         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 144)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 8)    10368       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 16, 16, 152)  0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 152)  608         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 152)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 8)    10944       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 16, 16, 160)  0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 160)  640         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 160)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 8)    11520       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 16, 16, 168)  0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 168)  672         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 168)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 8)    1344        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 8)      0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 8)      32          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 8, 8, 8)      0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 8, 8, 8)      576         activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 16)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 8, 8, 16)     64          concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 8, 8, 16)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 8, 8, 8)      1152        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 24)     0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 8, 8, 24)     96          concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 8, 8, 24)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 8, 8, 8)      1728        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 32)     0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 8, 8, 32)     128         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 8, 8, 32)     0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 8, 8, 8)      2304        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 40)     0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 8, 8, 40)     160         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 8, 8, 40)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 8, 8, 8)      2880        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 48)     0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 8, 8, 48)     192         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 8, 8, 48)     0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 8, 8, 8)      3456        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 56)     0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 8, 8, 56)     224         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 8, 8, 56)     0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 8, 8, 8)      4032        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 64)     0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 8, 8, 64)     0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 8, 8, 8)      4608        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 72)     0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 8, 8, 72)     288         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 8, 8, 72)     0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 8, 8, 8)      5184        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 8, 8, 80)     0           concatenate_47[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 80)     320         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 8, 8, 80)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 8, 8, 8)      5760        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 8, 8, 88)     0           concatenate_48[0][0]             \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 88)     352         concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 8, 8, 88)     0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 8, 8, 8)      6336        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 8, 8, 96)     0           concatenate_49[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 96)     384         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 96)     0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 8, 8, 8)      6912        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 8, 8, 104)    0           concatenate_50[0][0]             \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 104)    416         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 104)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 8, 8, 8)      7488        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 8, 8, 112)    0           concatenate_51[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 112)    448         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 112)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 8, 8, 8)      8064        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 8, 8, 120)    0           concatenate_52[0][0]             \n",
            "                                                                 conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 120)    480         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 8, 8, 120)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 8, 8, 8)      8640        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 8, 8, 128)    0           concatenate_53[0][0]             \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 8, 8, 128)    512         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 128)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 8, 8, 8)      9216        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 8, 8, 136)    0           concatenate_54[0][0]             \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 8, 8, 136)    544         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 8, 8, 136)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 8, 8, 8)      9792        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 8, 8, 144)    0           concatenate_55[0][0]             \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 8, 8, 144)    576         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 8, 8, 144)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 8, 8, 8)      10368       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 8, 8, 152)    0           concatenate_56[0][0]             \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 8, 8, 152)    608         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 8, 8, 152)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 8, 8, 8)      10944       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 8, 8, 160)    0           concatenate_57[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 8, 8, 160)    640         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 160)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 8, 8, 8)      11520       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 8, 8, 168)    0           concatenate_58[0][0]             \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 8, 8, 168)    672         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 168)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 8, 8, 8)      1344        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 8)      0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 4, 4, 8)      32          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 4, 4, 8)      0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 4, 4, 8)      576         activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 4, 4, 16)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 4, 4, 16)     64          concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 4, 4, 16)     0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 4, 4, 8)      1152        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 4, 4, 24)     0           concatenate_60[0][0]             \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 4, 4, 24)     96          concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 4, 4, 24)     0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 4, 4, 8)      1728        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 4, 4, 32)     0           concatenate_61[0][0]             \n",
            "                                                                 conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 4, 4, 32)     128         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 4, 4, 32)     0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 4, 4, 8)      2304        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 4, 4, 40)     0           concatenate_62[0][0]             \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 4, 4, 40)     160         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 4, 4, 40)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 4, 4, 8)      2880        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 4, 4, 48)     0           concatenate_63[0][0]             \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 4, 4, 48)     192         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 4, 4, 48)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 4, 4, 8)      3456        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 4, 4, 56)     0           concatenate_64[0][0]             \n",
            "                                                                 conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 4, 4, 56)     224         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 4, 4, 56)     0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 4, 4, 8)      4032        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 4, 4, 64)     0           concatenate_65[0][0]             \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 4, 4, 64)     256         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 4, 4, 64)     0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 4, 4, 8)      4608        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 4, 4, 72)     0           concatenate_66[0][0]             \n",
            "                                                                 conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 4, 4, 72)     288         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 4, 4, 72)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 4, 4, 8)      5184        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 4, 4, 80)     0           concatenate_67[0][0]             \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 80)     320         concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 80)     0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 4, 4, 8)      5760        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 4, 4, 88)     0           concatenate_68[0][0]             \n",
            "                                                                 conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 88)     352         concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 88)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 4, 4, 8)      6336        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 4, 4, 96)     0           concatenate_69[0][0]             \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 96)     384         concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 96)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 4, 4, 8)      6912        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 4, 4, 104)    0           concatenate_70[0][0]             \n",
            "                                                                 conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 104)    416         concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 104)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 4, 4, 8)      7488        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 4, 4, 112)    0           concatenate_71[0][0]             \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 4, 4, 112)    448         concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 112)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 4, 4, 8)      8064        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 4, 4, 120)    0           concatenate_72[0][0]             \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 4, 4, 120)    480         concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 120)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 4, 4, 8)      8640        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 4, 4, 128)    0           concatenate_73[0][0]             \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 4, 4, 128)    512         concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 128)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 4, 4, 8)      9216        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 4, 4, 136)    0           concatenate_74[0][0]             \n",
            "                                                                 conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 4, 4, 136)    544         concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 136)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 4, 4, 8)      9792        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 4, 4, 144)    0           concatenate_75[0][0]             \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 4, 4, 144)    576         concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 4, 4, 144)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 4, 4, 8)      10368       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 4, 4, 152)    0           concatenate_76[0][0]             \n",
            "                                                                 conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 4, 4, 152)    608         concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 4, 4, 152)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 4, 4, 8)      10944       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 4, 4, 160)    0           concatenate_77[0][0]             \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 4, 4, 160)    640         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 4, 4, 160)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 4, 4, 8)      11520       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 4, 4, 168)    0           concatenate_78[0][0]             \n",
            "                                                                 conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 4, 4, 168)    672         concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 4, 4, 168)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 168)    0           activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 672)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           6730        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 536,858\n",
            "Trainable params: 521,738\n",
            "Non-trainable params: 15,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae4ypTq-JcQb",
        "outputId": "8b554693-f7e1-4e3d-929c-528eb91f70fe"
      },
      "source": [
        "model_1 = model.fit(datagen.flow(X_train, y_train, batch_size = 64),epochs = 100, \n",
        "                                 validation_data = (X_test, y_test), verbose=1,callbacks=[earlystopping,checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 522s 622ms/step - loss: 1.6956 - accuracy: 0.3756 - val_loss: 1.5209 - val_accuracy: 0.4657\n",
            "\n",
            "Epoch 00001: saving model to weights.hdf5\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 444s 568ms/step - loss: 1.3175 - accuracy: 0.5238 - val_loss: 1.3223 - val_accuracy: 0.5282\n",
            "\n",
            "Epoch 00002: saving model to weights.hdf5\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 437s 559ms/step - loss: 1.1201 - accuracy: 0.5971 - val_loss: 1.2434 - val_accuracy: 0.5682\n",
            "\n",
            "Epoch 00003: saving model to weights.hdf5\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 486s 622ms/step - loss: 1.0039 - accuracy: 0.6401 - val_loss: 1.3250 - val_accuracy: 0.5582\n",
            "\n",
            "Epoch 00004: saving model to weights.hdf5\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 445s 569ms/step - loss: 0.9048 - accuracy: 0.6782 - val_loss: 1.5561 - val_accuracy: 0.5275\n",
            "\n",
            "Epoch 00005: saving model to weights.hdf5\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 486s 622ms/step - loss: 0.8367 - accuracy: 0.7036 - val_loss: 0.9251 - val_accuracy: 0.6876\n",
            "\n",
            "Epoch 00006: saving model to weights.hdf5\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 439s 561ms/step - loss: 0.7721 - accuracy: 0.7284 - val_loss: 1.1087 - val_accuracy: 0.6529\n",
            "\n",
            "Epoch 00007: saving model to weights.hdf5\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 440s 563ms/step - loss: 0.7186 - accuracy: 0.7464 - val_loss: 0.8780 - val_accuracy: 0.7067\n",
            "\n",
            "Epoch 00008: saving model to weights.hdf5\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 442s 565ms/step - loss: 0.6833 - accuracy: 0.7613 - val_loss: 1.3069 - val_accuracy: 0.6265\n",
            "\n",
            "Epoch 00009: saving model to weights.hdf5\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 486s 622ms/step - loss: 0.6517 - accuracy: 0.7715 - val_loss: 0.8754 - val_accuracy: 0.7193\n",
            "\n",
            "Epoch 00010: saving model to weights.hdf5\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 446s 570ms/step - loss: 0.6143 - accuracy: 0.7845 - val_loss: 0.7605 - val_accuracy: 0.7504\n",
            "\n",
            "Epoch 00011: saving model to weights.hdf5\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 438s 560ms/step - loss: 0.5910 - accuracy: 0.7938 - val_loss: 0.8800 - val_accuracy: 0.7108\n",
            "\n",
            "Epoch 00012: saving model to weights.hdf5\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 439s 562ms/step - loss: 0.5655 - accuracy: 0.8026 - val_loss: 0.7006 - val_accuracy: 0.7689\n",
            "\n",
            "Epoch 00013: saving model to weights.hdf5\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 440s 562ms/step - loss: 0.5422 - accuracy: 0.8125 - val_loss: 0.6494 - val_accuracy: 0.7815\n",
            "\n",
            "Epoch 00014: saving model to weights.hdf5\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 435s 556ms/step - loss: 0.5204 - accuracy: 0.8200 - val_loss: 0.7285 - val_accuracy: 0.7603\n",
            "\n",
            "Epoch 00015: saving model to weights.hdf5\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 437s 558ms/step - loss: 0.5026 - accuracy: 0.8252 - val_loss: 0.6046 - val_accuracy: 0.7947\n",
            "\n",
            "Epoch 00016: saving model to weights.hdf5\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 440s 563ms/step - loss: 0.4910 - accuracy: 0.8297 - val_loss: 0.7000 - val_accuracy: 0.7688\n",
            "\n",
            "Epoch 00017: saving model to weights.hdf5\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 439s 561ms/step - loss: 0.4726 - accuracy: 0.8370 - val_loss: 0.7529 - val_accuracy: 0.7626\n",
            "\n",
            "Epoch 00018: saving model to weights.hdf5\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 438s 560ms/step - loss: 0.4590 - accuracy: 0.8404 - val_loss: 0.8051 - val_accuracy: 0.7442\n",
            "\n",
            "Epoch 00019: saving model to weights.hdf5\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 439s 561ms/step - loss: 0.4405 - accuracy: 0.8471 - val_loss: 0.7540 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00020: saving model to weights.hdf5\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 483s 618ms/step - loss: 0.4336 - accuracy: 0.8496 - val_loss: 0.7294 - val_accuracy: 0.7762\n",
            "\n",
            "Epoch 00021: saving model to weights.hdf5\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 449s 574ms/step - loss: 0.4217 - accuracy: 0.8548 - val_loss: 0.5809 - val_accuracy: 0.8084\n",
            "\n",
            "Epoch 00022: saving model to weights.hdf5\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 491s 629ms/step - loss: 0.4099 - accuracy: 0.8569 - val_loss: 0.5145 - val_accuracy: 0.8305\n",
            "\n",
            "Epoch 00023: saving model to weights.hdf5\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 452s 578ms/step - loss: 0.3992 - accuracy: 0.8608 - val_loss: 0.5815 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00024: saving model to weights.hdf5\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 450s 575ms/step - loss: 0.3951 - accuracy: 0.8625 - val_loss: 0.5940 - val_accuracy: 0.8101\n",
            "\n",
            "Epoch 00025: saving model to weights.hdf5\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 440s 563ms/step - loss: 0.3863 - accuracy: 0.8660 - val_loss: 0.6127 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00026: saving model to weights.hdf5\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 440s 563ms/step - loss: 0.3769 - accuracy: 0.8692 - val_loss: 0.4847 - val_accuracy: 0.8412\n",
            "\n",
            "Epoch 00027: saving model to weights.hdf5\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 442s 565ms/step - loss: 0.3692 - accuracy: 0.8704 - val_loss: 0.6852 - val_accuracy: 0.7880\n",
            "\n",
            "Epoch 00028: saving model to weights.hdf5\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 440s 562ms/step - loss: 0.3627 - accuracy: 0.8739 - val_loss: 0.4553 - val_accuracy: 0.8467\n",
            "\n",
            "Epoch 00029: saving model to weights.hdf5\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 443s 566ms/step - loss: 0.3553 - accuracy: 0.8759 - val_loss: 0.5178 - val_accuracy: 0.8316\n",
            "\n",
            "Epoch 00030: saving model to weights.hdf5\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 442s 565ms/step - loss: 0.3473 - accuracy: 0.8776 - val_loss: 0.4423 - val_accuracy: 0.8504\n",
            "\n",
            "Epoch 00031: saving model to weights.hdf5\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 487s 623ms/step - loss: 0.3432 - accuracy: 0.8800 - val_loss: 0.6837 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00032: saving model to weights.hdf5\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 447s 572ms/step - loss: 0.3317 - accuracy: 0.8848 - val_loss: 0.5253 - val_accuracy: 0.8317\n",
            "\n",
            "Epoch 00033: saving model to weights.hdf5\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 446s 570ms/step - loss: 0.3273 - accuracy: 0.8857 - val_loss: 0.4270 - val_accuracy: 0.8585\n",
            "\n",
            "Epoch 00034: saving model to weights.hdf5\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 488s 624ms/step - loss: 0.3207 - accuracy: 0.8876 - val_loss: 0.7824 - val_accuracy: 0.7801\n",
            "\n",
            "Epoch 00035: saving model to weights.hdf5\n",
            "Epoch 36/100\n",
            "553/782 [====================>.........] - ETA: 1:59 - loss: 0.3097 - accuracy: 0.8915"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re9bwMGAiKb5"
      },
      "source": [
        "### Colab runtime disconnected on epoch 36 loading the saved model. and restaring the training from 36\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ysJ1sXXOzKD",
        "outputId": "a1957e0b-84d3-48f0-b6b9-812e5c14c9ff"
      },
      "source": [
        "model.load_weights(\"./weights.hdf5\")\n",
        "print(\"Weights Loaded\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA2-f54fjNlk"
      },
      "source": [
        "filepath=\"weights_2.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.03)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIJx5nqhidE6",
        "outputId": "6bebdaf8-1987-461f-a31f-2ac1e92b75b6"
      },
      "source": [
        "model_1 = model.fit(datagen.flow(X_train, y_train, batch_size = 64),epochs = 20, \n",
        "                                 validation_data = (X_test, y_test), verbose=1,callbacks=[earlystopping,checkpoint])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 495s 633ms/step - loss: 0.3298 - accuracy: 0.8834 - val_loss: 0.6518 - val_accuracy: 0.8048\n",
            "\n",
            "Epoch 00001: saving model to weights_2.hdf5\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 452s 578ms/step - loss: 0.3273 - accuracy: 0.8842 - val_loss: 0.4485 - val_accuracy: 0.8560\n",
            "\n",
            "Epoch 00002: saving model to weights_2.hdf5\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 446s 570ms/step - loss: 0.3189 - accuracy: 0.8890 - val_loss: 0.4523 - val_accuracy: 0.8488\n",
            "\n",
            "Epoch 00003: saving model to weights_2.hdf5\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 453s 580ms/step - loss: 0.3075 - accuracy: 0.8922 - val_loss: 0.4626 - val_accuracy: 0.8504\n",
            "\n",
            "Epoch 00004: saving model to weights_2.hdf5\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 455s 582ms/step - loss: 0.3074 - accuracy: 0.8927 - val_loss: 0.4823 - val_accuracy: 0.8426\n",
            "\n",
            "Epoch 00005: saving model to weights_2.hdf5\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 447s 572ms/step - loss: 0.3040 - accuracy: 0.8936 - val_loss: 0.5142 - val_accuracy: 0.8417\n",
            "\n",
            "Epoch 00006: saving model to weights_2.hdf5\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 445s 570ms/step - loss: 0.2992 - accuracy: 0.8952 - val_loss: 0.7051 - val_accuracy: 0.7985\n",
            "\n",
            "Epoch 00007: saving model to weights_2.hdf5\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 492s 629ms/step - loss: 0.2968 - accuracy: 0.8956 - val_loss: 0.4946 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00008: saving model to weights_2.hdf5\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 493s 631ms/step - loss: 0.2915 - accuracy: 0.8982 - val_loss: 0.6102 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00009: saving model to weights_2.hdf5\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 454s 580ms/step - loss: 0.2824 - accuracy: 0.9020 - val_loss: 0.4538 - val_accuracy: 0.8587\n",
            "\n",
            "Epoch 00010: saving model to weights_2.hdf5\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 451s 577ms/step - loss: 0.2823 - accuracy: 0.9005 - val_loss: 0.4813 - val_accuracy: 0.8496\n",
            "\n",
            "Epoch 00011: saving model to weights_2.hdf5\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 450s 575ms/step - loss: 0.2752 - accuracy: 0.9015 - val_loss: 0.6483 - val_accuracy: 0.8087\n",
            "\n",
            "Epoch 00012: saving model to weights_2.hdf5\n",
            "Epoch 00012: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEtMbusWCpu7"
      },
      "source": [
        "### Accuracy is not improving beyond 0.84. So training was stopped with early stopping techinque in calback  on epoch 44 (32+12) and  loading the saved model, restaring the training with adaptive learning rate, ie. reducing the learning with each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTvGQ3yVCpJf",
        "outputId": "a689d82c-a804-4644-e672-2bac2db0eac2"
      },
      "source": [
        "model.load_weights(\"weights_2.hdf5\")\n",
        "print(\"Weights Loaded\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMyZs5HUDdue"
      },
      "source": [
        "filepath=\"weights_3.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlDit2JzjTav"
      },
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=2,verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY_tHfX6Dqm-",
        "outputId": "04869415-bf20-4eb4-b6a2-ef643a10238f"
      },
      "source": [
        "model_1 = model.fit(datagen.flow(X_train, y_train, batch_size = 128),epochs = 20, \n",
        "                                 validation_data = (X_test, y_test), verbose=1,callbacks=[earlystopping,checkpoint,lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 414s 966ms/step - loss: 0.2342 - accuracy: 0.9182 - val_loss: 0.4517 - val_accuracy: 0.8605\n",
            "\n",
            "Epoch 00001: saving model to weights_3.hdf5\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 378s 967ms/step - loss: 0.2239 - accuracy: 0.9210 - val_loss: 0.4564 - val_accuracy: 0.8623\n",
            "\n",
            "Epoch 00002: saving model to weights_3.hdf5\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 336s 859ms/step - loss: 0.2197 - accuracy: 0.9224 - val_loss: 0.4992 - val_accuracy: 0.8511\n",
            "\n",
            "Epoch 00003: saving model to weights_3.hdf5\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 332s 849ms/step - loss: 0.1801 - accuracy: 0.9368 - val_loss: 0.3609 - val_accuracy: 0.8864\n",
            "\n",
            "Epoch 00004: saving model to weights_3.hdf5\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 336s 860ms/step - loss: 0.1717 - accuracy: 0.9405 - val_loss: 0.3720 - val_accuracy: 0.8846\n",
            "\n",
            "Epoch 00005: saving model to weights_3.hdf5\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 336s 858ms/step - loss: 0.1658 - accuracy: 0.9409 - val_loss: 0.3442 - val_accuracy: 0.8920\n",
            "\n",
            "Epoch 00006: saving model to weights_3.hdf5\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 335s 856ms/step - loss: 0.1643 - accuracy: 0.9426 - val_loss: 0.3528 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00007: saving model to weights_3.hdf5\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 333s 852ms/step - loss: 0.1620 - accuracy: 0.9441 - val_loss: 0.3420 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00008: saving model to weights_3.hdf5\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 377s 966ms/step - loss: 0.1581 - accuracy: 0.9434 - val_loss: 0.3656 - val_accuracy: 0.8865\n",
            "\n",
            "Epoch 00009: saving model to weights_3.hdf5\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 377s 963ms/step - loss: 0.1553 - accuracy: 0.9450 - val_loss: 0.3473 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00010: saving model to weights_3.hdf5\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 336s 859ms/step - loss: 0.1545 - accuracy: 0.9452 - val_loss: 0.3433 - val_accuracy: 0.8961\n",
            "\n",
            "Epoch 00011: saving model to weights_3.hdf5\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 334s 854ms/step - loss: 0.1543 - accuracy: 0.9458 - val_loss: 0.3439 - val_accuracy: 0.8961\n",
            "\n",
            "Epoch 00012: saving model to weights_3.hdf5\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 333s 852ms/step - loss: 0.1536 - accuracy: 0.9474 - val_loss: 0.3432 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00013: saving model to weights_3.hdf5\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 336s 858ms/step - loss: 0.1547 - accuracy: 0.9446 - val_loss: 0.3441 - val_accuracy: 0.8957\n",
            "\n",
            "Epoch 00014: saving model to weights_3.hdf5\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 334s 854ms/step - loss: 0.1535 - accuracy: 0.9468 - val_loss: 0.3441 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 00015: saving model to weights_3.hdf5\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 333s 851ms/step - loss: 0.1508 - accuracy: 0.9469 - val_loss: 0.3427 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00016: saving model to weights_3.hdf5\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 336s 860ms/step - loss: 0.1529 - accuracy: 0.9459 - val_loss: 0.3436 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00017: saving model to weights_3.hdf5\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 336s 859ms/step - loss: 0.1549 - accuracy: 0.9452 - val_loss: 0.3432 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 00018: saving model to weights_3.hdf5\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 333s 853ms/step - loss: 0.1532 - accuracy: 0.9462 - val_loss: 0.3438 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00019: saving model to weights_3.hdf5\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 334s 855ms/step - loss: 0.1534 - accuracy: 0.9459 - val_loss: 0.3445 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 00020: saving model to weights_3.hdf5\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIDdA5YxEGQV",
        "outputId": "e2599e0d-9a9a-4993-9113-bc4d864545e4"
      },
      "source": [
        "\n",
        "from prettytable import PrettyTable \n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Model\", \"Train AUC\", \"Test AUC\"]\n",
        "table.add_row([\"Model\", \"0.93\", \"0.9\"])\n",
        "# table.add_row([\"Model2\", \"0.816\", \"0.72\"])\n",
        "# table.add_row([\"Model3\", \"0.893\", \"0.72\"])\n",
        "print(table)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----------+----------+\n",
            "| Model | Train AUC | Test AUC |\n",
            "+-------+-----------+----------+\n",
            "| Model |    0.93   |   0.9    |\n",
            "+-------+-----------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kIyIpZYboiPG",
        "outputId": "40b3c436-c680-4be6-e7d0-a3811d1cc62d"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def accuracy_plot(history):\n",
        " plt.xlabel('epochs')\n",
        " plt.ylabel('accuracy')\n",
        " plt.title('AUC vs epoch')\n",
        " plt.plot(history.history['accuracy'], color='green', label='train')\n",
        " plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " plt.legend(loc =\"lower right\")\n",
        " plt.show()\n",
        "accuracy_plot(model_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmojQ4rXt5MX"
      },
      "source": [
        "CIFAR 10 assignmnet was done with following restrictions:\n",
        "1. No.of trainable parameters < 1 Million\n",
        "2. No droput layers were included\n",
        "3. No. of epoch was less than 300\n",
        "\n",
        "Multiple experiments were carried out to come up with test accurcay of 90%. I had tried changing no. of filters, kernel initalization technique, optmizers etc.\n",
        "\n",
        "Given dataset size was increased for training by using image augmentation techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BQ7WgDMVfzJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}